# -*- coding: utf-8 -*-
"""Credit_Card_Trans_Extract_App.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DKuT2JWfZ9meyKi0-TmUhQ4P5a-7wPkB
"""

!pip install pdfplumber
!pip install streamlit

import streamlit as st
import pdfplumber
import pandas as pd
import re
from io import BytesIO

def extract_transactions_from_pdf(file):
    transactions = []

    with pdfplumber.open(file) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            if not text:
                continue
            lines = text.split('\n')
            for line in lines:
                match = re.search(
                    r'(\d{1,2} \w{3} 2025)\s+([A-Z0-9\-\*\s\(\)\.]+?)\s+(\d{1,3}(?:,\d{3})*\.\d{2})',
                    line
                )
                if match:
                    date = match.group(1)
                    location = match.group(2).strip()
                    amount = match.group(3).replace(',', '')
                    transactions.append([date, location, float(amount)])
    return transactions

# Streamlit app interface
st.set_page_config(page_title="Credit Card Transaction Extractor", layout="centered")
st.title("üìÑ Credit Card Transaction Extractor")

uploaded_files = st.file_uploader("Upload PDF statements", type="pdf", accept_multiple_files=True)

if uploaded_files:
    all_data = []

    for file in uploaded_files:
        extracted = extract_transactions_from_pdf(BytesIO(file.read()))
        all_data.extend(extracted)

    if all_data:
        df = pd.DataFrame(all_data, columns=["Transaction Date", "Location", "Amount (PKR)"])
        st.success(f"‚úÖ Extracted {len(df)} transactions.")
        st.dataframe(df)

        # Download button
        csv = df.to_csv(index=False).encode('utf-8')
        st.download_button("üì• Download CSV", data=csv, file_name="transactions.csv", mime="text/csv")
    else:
        st.warning("‚ö†Ô∏è No valid transactions found in uploaded PDFs.")

# prompt: Analyze above code and suggest if anything is wrong

Based on the provided code, here's an analysis and suggestions for potential issues or improvements, keeping in mind that the code is intended for a Colaboratory/Jupyter environment and uses Streamlit (which typically runs as a separate application):

1.  **Streamlit in Colab/Jupyter:** The primary issue is that this code is designed to run as a Streamlit application. Streamlit requires its own server and environment. Running `import streamlit as st` directly in a standard Colab or Jupyter notebook cell will not start the Streamlit server and display the interactive UI. You need a separate setup to run Streamlit applications.
    *   **Suggestion:** If the goal is to build a Streamlit app, you need to save this code as a `.py` file and run it from the terminal using `streamlit run your_script_name.py`. If the goal is to use this within Colab/Jupyter, the Streamlit part (`st.set_page_config`, `st.title`, `st.file_uploader`, `st.success`, `st.dataframe`, `st.download_button`) is incompatible with the standard notebook execution flow. You would need to remove or adapt these parts to work with standard notebook output or libraries like `ipywidgets` if you want interactive elements.

2.  **Shell Commands (`!pip install`) within the Script:** While Colab/Jupyter allows shell commands like `!pip install`, placing them directly inside the Python script itself is generally not the best practice. Installations should typically happen *before* the script execution or in a separate notebook cell. Running `!pip install` every time the script is executed is inefficient and unnecessary.
    *   **Suggestion:** Remove the `!pip install pdfplumber` and `!pip install streamlit` lines from the Python code block. These installations should be done in separate cells *before* running the code that uses these libraries.

3.  **PDF File Handling for `pdfplumber`:** The `extract_transactions_from_pdf` function takes `file` as an argument and expects it to be something that `pdfplumber.open()` can directly handle. When using `st.file_uploader`, `file` is a `UploadedFile` object. The line `BytesIO(file.read())` correctly wraps the file content in a `BytesIO` object, which `pdfplumber.open()` *can* typically accept, so this part seems okay. However, it's good practice to ensure `pdfplumber.open()` is compatible with `BytesIO` objects representing binary PDF data. (It generally is).

4.  **Regex Robustness:** The regex `r'(\d{1,2} \w{3} 2025)\s+([A-Z0-9\-\*\s\(\)\.]+?)\s+(\d{1,3}(?:,\d{3})*\.\d{2})'` is specific to a date format like "DD Mon 2025" and a currency format like "X,XXX.XX".
    *   **Suggestion:** If the year in the date is not always "2025", you should make that part of the regex more flexible (e.g., `\d{4}` for any four-digit year).
    *   The location part `([A-Z0-9\-\*\s\(\)\.]+?)` is quite broad. It might incorrectly capture text that is not the location if the spacing or format varies significantly in the PDF. If possible, refine this pattern based on more examples of the PDF layout.
    *   The currency pattern `(\d{1,3}(?:,\d{3})*\.\d{2})` handles commas correctly.
    *   Consider edge cases where transaction lines might span multiple lines in the PDF or have different formats. More complex parsing logic might be needed for less consistent PDF layouts.

5.  **Error Handling:** There is minimal error handling. If `pdfplumber.open()` fails, if `file.read()` fails, or if the regex never matches any lines, the code might produce unexpected results or errors.
    *   **Suggestion:** Add `try...except` blocks around file operations and potentially the regex matching loop to catch exceptions (e.g., `IOError`, `re.error`) and provide user-friendly messages.

6.  **Year Specificity in Date Parsing:** The regex `(\d{1,2} \w{3} 2025)` hardcodes the year "2025". This will only work for statements from that specific year.
    *   **Suggestion:** Modify the regex to accept any four-digit year (`\d{4}`) and parse the full date string into a proper date object (e.g., using `datetime.strptime`) to handle different years correctly.

In summary, the core logic for extracting data using `pdfplumber` and regex seems plausible *for the specific format* it's designed for. The main problem is the integration with Streamlit, which won't work as written in a standard Colab/Jupyter environment. The shell commands for installation should also be moved outside the main code block.



